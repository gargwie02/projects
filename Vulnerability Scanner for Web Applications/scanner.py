from crawler import crawl
from vulnerability_tests import xss, sqli, headers
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

target = input("Enter the target URL: ").strip()
if not target.startswith("http"):
    target = "http://" + target

try:
    urls = crawl(target)
    print(f"Scanning {len(urls)} URLs...\n")

    for url in urls:
        sqli_result = sqli.test_sql_injection(url)
        xss_result = xss.test_xss(url)
        header_issues = headers.check_headers(url)

        if sqli_result:
            print("[SQLi] " + sqli_result)
        if xss_result:
            print("[XSS] " + xss_result)
        if header_issues:
            print(f"[Headers] {url} => " + "; ".join(header_issues))

except Exception as e:
    print(f"Error scanning URL: {e}")
